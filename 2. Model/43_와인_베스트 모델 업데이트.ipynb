{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베스트 모델 만들기 - 와인 사례\n",
    "## 이진 분류\n",
    "## 베스트 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "df_pre = pd.read_csv('../dataset/wine.csv', header=None)\n",
    "df = df_pre.sample(frac=1)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(30, input_dim=12, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model1/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"best{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29602, saving model to ./model1/best001-0.2960.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29602 to 0.25399, saving model to ./model1/best002-0.2540.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25399 to 0.23458, saving model to ./model1/best003-0.2346.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23458 to 0.21686, saving model to ./model1/best004-0.2169.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21686 to 0.20170, saving model to ./model1/best005-0.2017.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20170 to 0.19476, saving model to ./model1/best006-0.1948.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19476 to 0.19266, saving model to ./model1/best007-0.1927.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.19266 to 0.18813, saving model to ./model1/best008-0.1881.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18813 to 0.18613, saving model to ./model1/best009-0.1861.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18613 to 0.18426, saving model to ./model1/best010-0.1843.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18426 to 0.18331, saving model to ./model1/best011-0.1833.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18331 to 0.18164, saving model to ./model1/best012-0.1816.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18164\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18164 to 0.17874, saving model to ./model1/best014-0.1787.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17874 to 0.17391, saving model to ./model1/best015-0.1739.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17391 to 0.17197, saving model to ./model1/best016-0.1720.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.17197 to 0.17007, saving model to ./model1/best017-0.1701.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.17007 to 0.16759, saving model to ./model1/best018-0.1676.hdf5\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16759\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.16759 to 0.15922, saving model to ./model1/best020-0.1592.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15922 to 0.15323, saving model to ./model1/best021-0.1532.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15323\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15323 to 0.15250, saving model to ./model1/best023-0.1525.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15250 to 0.14549, saving model to ./model1/best024-0.1455.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14549 to 0.13897, saving model to ./model1/best025-0.1390.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.13897\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13897\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.13897 to 0.13744, saving model to ./model1/best028-0.1374.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13744 to 0.12927, saving model to ./model1/best029-0.1293.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12927 to 0.12490, saving model to ./model1/best030-0.1249.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.12490\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12490 to 0.12304, saving model to ./model1/best032-0.1230.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12304 to 0.11524, saving model to ./model1/best033-0.1152.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11524 to 0.11357, saving model to ./model1/best034-0.1136.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11357\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11357 to 0.11269, saving model to ./model1/best036-0.1127.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11269 to 0.10775, saving model to ./model1/best037-0.1078.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.10775\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.10775 to 0.10228, saving model to ./model1/best039-0.1023.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10228\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.10228 to 0.09935, saving model to ./model1/best041-0.0994.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.09935 to 0.09574, saving model to ./model1/best042-0.0957.hdf5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.09574\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.09574\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.09574\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.09574\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09574\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.09574\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.09574 to 0.09071, saving model to ./model1/best049-0.0907.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.09071 to 0.08652, saving model to ./model1/best050-0.0865.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08652 to 0.08456, saving model to ./model1/best051-0.0846.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08456 to 0.08290, saving model to ./model1/best052-0.0829.hdf5\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.08290\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08290\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08290 to 0.08142, saving model to ./model1/best055-0.0814.hdf5\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.08142\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.08142 to 0.07780, saving model to ./model1/best057-0.0778.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07780\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.07780\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07780 to 0.07494, saving model to ./model1/best060-0.0749.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.07494 to 0.07386, saving model to ./model1/best061-0.0739.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.07386 to 0.07290, saving model to ./model1/best062-0.0729.hdf5\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07290\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07290 to 0.07173, saving model to ./model1/best064-0.0717.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07173\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07173 to 0.07058, saving model to ./model1/best066-0.0706.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.07058 to 0.06910, saving model to ./model1/best067-0.0691.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.06910\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.06910 to 0.06904, saving model to ./model1/best069-0.0690.hdf5\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.06904 to 0.06703, saving model to ./model1/best070-0.0670.hdf5\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06703\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06703\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.06703 to 0.06562, saving model to ./model1/best073-0.0656.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06562 to 0.06504, saving model to ./model1/best074-0.0650.hdf5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06504\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.06504 to 0.06439, saving model to ./model1/best076-0.0644.hdf5\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06439\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06439\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06439\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06439\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.06439\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06439 to 0.06252, saving model to ./model1/best082-0.0625.hdf5\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06252\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06252\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.06252 to 0.06187, saving model to ./model1/best085-0.0619.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06187 to 0.06153, saving model to ./model1/best086-0.0615.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.06153 to 0.06122, saving model to ./model1/best087-0.0612.hdf5\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.06122 to 0.06035, saving model to ./model1/best089-0.0604.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06035\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06035\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06035\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.06035\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.06035 to 0.06000, saving model to ./model1/best094-0.0600.hdf5\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.06000\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.06000 to 0.05912, saving model to ./model1/best098-0.0591.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05912 to 0.05879, saving model to ./model1/best099-0.0588.hdf5\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.05879 to 0.05791, saving model to ./model1/best100-0.0579.hdf5\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.05791\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05791\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05791\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_loss did not improve from 0.05791\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.05791 to 0.05779, saving model to ./model1/best106-0.0578.hdf5\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05779\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05779\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05779\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05779\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.05779 to 0.05688, saving model to ./model1/best111-0.0569.hdf5\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05688\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05688\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05688\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.05688 to 0.05671, saving model to ./model1/best115-0.0567.hdf5\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05671\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.05671 to 0.05574, saving model to ./model1/best119-0.0557.hdf5\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05574\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05574\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05574\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05574\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.05574 to 0.05474, saving model to ./model1/best124-0.0547.hdf5\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05474\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.05474 to 0.05468, saving model to ./model1/best144-0.0547.hdf5\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.05468\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.05468 to 0.05420, saving model to ./model1/best159-0.0542.hdf5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OSError' object has no attribute 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1008\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 112\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    113\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = './model1/best159-0.0542.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-da8fc64cc809>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 모델 실행 및 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, \n\u001b[1;32m----> 3\u001b[1;33m           verbose=0, callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1043\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# `e.errno` appears to be `None` so checking the content of `e.message`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;34m'is a directory'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m           raise IOError('Please specify a non-directory filepath for '\n\u001b[0;32m   1047\u001b[0m                         \u001b[1;34m'ModelCheckpoint. Filepath used is an existing '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OSError' object has no attribute 'message'"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, \n",
    "          verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model1/best192-0.0530.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델의 결과 출력 \n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
